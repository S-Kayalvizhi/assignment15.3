1.Explain the working of SQOOP in brief.

Sqoop: “SQL to Hadoop and Hadoop to SQL”

Sqoop is a tool designed to transfer data between Hadoop and relational database servers.
It is used to import data from relational databases such as MySQL, Oracle to Hadoop HDFS, and export from Hadoop file system to relational databases.
It is provided by the Apache Software Foundation.
Sqoop automates most of this process, relying on the database to describe the schema for the data to be imported. 
Sqoop uses MapReduce to import and export the data, which provides parallel operation as well as fault tolerance.
This document describes how to get started using Sqoop to move data between databases and Hadoop and provides reference information for the operation of the Sqoop command-line tool suite.
This document is intended for:
*System and application programmers
*System administrators
*Database administrators
*Data analysts
*Data engineers

Sqoop Import:
The import tool imports individual tables from RDBMS to HDFS.
Each row in a table is treated as a record in HDFS. 
All records are stored as text data in text files or as binary data in Avro and Sequence files.

Sqoop Export:
The export tool exports a set of files from HDFS back to an RDBMS.
The files given as input to Sqoop contain records, which are called as rows in table.
Those are read and parsed into a set of records and delimited with user-specified delimiter.



2.Import a table from Mysql to HBase table using Sqoop.

* Start the Mysql service using the command:
   => sudo service mysqld start

* Login to MySQL shell:
   => mysql -u root -p
   => Password

* Show databases:
   => show databases;

* Use database:
   => use database_name;

* Show tables:
   => show tables;

* Describe table:
   => desc table_name;
